{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add Path and read movie list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path('/home/jianghui/dataset/MovieNet-Subset/')\n",
    "\n",
    "tt_list = []\n",
    "with open(Path(root_path, 'movie_id_list'), 'r') as f_tt_list:\n",
    "    for tt_line in f_tt_list:\n",
    "        tt_list.append(tt_line.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_path = Path('/home/jianghui/dataset/MovieNet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read shot.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "    print(f'processing {tt_id} ...')\n",
    "    # read shot file\n",
    "    shot_path = Path(root_path, 'all/shot/', f'{tt_id}.json')\n",
    "    with open(shot_path, 'r') as f_shot:\n",
    "        shot_json = json.load(f_shot)\n",
    "    \n",
    "    # make up subtitle file\n",
    "    subtitle_json = []\n",
    "    for shot_element in shot_json:\n",
    "        subtitle_idx = 0\n",
    "        if shot_element['subtitle_start_id'] == None : continue \n",
    "        for i, subtitle_id in enumerate(range(int(shot_element['subtitle_start_id']), int(shot_element['subtitle_end_id'] + 1))):\n",
    "            if subtitle_id < subtitle_idx: continue\n",
    "            subtitle_element = {'subtitle_id':subtitle_id, 'scentence':shot_element['subtitle'][i]}\n",
    "            subtitle_json.append(subtitle_element)\n",
    "            subtitle_idx += 1\n",
    "\n",
    "    # save subtitle file\n",
    "    subtitle_path = Path(root_path, 'all/subtitle', f'{tt_id}.json')\n",
    "    with open(subtitle_path, 'w') as f_subtitle:\n",
    "        json.dump(subtitle_json, f_subtitle, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. clean shot.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "    print(f'processing {tt_id} ...')\n",
    "    # read shot file\n",
    "    shot_path = Path(root_path, 'all/shot/', f'{tt_id}.json')\n",
    "    with open(shot_path, 'r') as f_shot:\n",
    "        shot_json = json.load(f_shot)\n",
    "    \n",
    "    for shot_element in shot_json:\n",
    "        if shot_element['subtitle_id'][0] == None:\n",
    "            shot_element['subtitle_id'] = []\n",
    "        # if \"subtitle\" not in shot_element: continue\n",
    "\n",
    "        # # change subtitle_id format\n",
    "        # subtitle_id = []\n",
    "        # subtitle_id.append(shot_element['subtitle_start_id'])\n",
    "        # subtitle_id.append(shot_element['subtitle_end_id'])\n",
    "        # shot_element['subtitle_id'] = subtitle_id\n",
    "\n",
    "        # # pop subtitle\n",
    "        # shot_element.pop('subtitle')\n",
    "        # shot_element.pop('subtitle_start_id')\n",
    "        # shot_element.pop('subtitle_end_id')\n",
    "    \n",
    "    if DEBUG : print(shot_json)\n",
    "    # save shot file\n",
    "    with open(shot_path, 'w') as f_shot:\n",
    "        json.dump(shot_json, f_shot, indent=2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. re_order tt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list.sort()\n",
    "tt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(root_path, 'movie_id_list'), 'w') as f_tt_list:\n",
    "    for tt_line in tt_list:\n",
    "        f_tt_list.write(tt_line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. add movie_info with subtitle_num, shot_num, scene_num, synopsis_num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_path = Path(root_path, 'movie_info.json')\n",
    "with open(info_path, 'r') as f_info:\n",
    "    info_json = json.load(f_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info_elem_key in info_json:\n",
    "    info_json[info_elem_key]['subtitle_num'] = None\n",
    "    info_json[info_elem_key]['shot_num'] = None\n",
    "    info_json[info_elem_key]['scene_num'] = None\n",
    "    info_json[info_elem_key]['synopsis_num'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "\n",
    "    subtitle_path = Path(root_path, 'all/subtitle', f'{tt_id}.json')\n",
    "    with open(subtitle_path, 'r') as f_subtitle:\n",
    "        subtitle_json = json.load(f_subtitle)\n",
    "\n",
    "    shot_path = Path(root_path, 'all/shot', f'{tt_id}.json')\n",
    "    with open(shot_path, 'r') as f_shot:\n",
    "        shot_json = json.load(f_shot)\n",
    "\n",
    "    scene_path = Path(root_path, 'all/scene', f'{tt_id}.json')\n",
    "    with open(scene_path, 'r') as f_scene:\n",
    "        scene_json = json.load(f_scene)\n",
    "\n",
    "    info_json[tt_id]['subtitle_num'] = int(subtitle_json[-1]['subtitle_id']) + 1\n",
    "    info_json[tt_id]['shot_num'] = int(shot_json[-1]['shot_id']) + 1\n",
    "    info_json[tt_id]['scene_num'] = int(scene_json[-1]['scene_id']) + 1\n",
    "\n",
    "    if DEBUG :\n",
    "        print(info_json)\n",
    "    else:\n",
    "        with open(info_path, 'w') as f_info:\n",
    "            json.dump(info_json, f_info, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. aligned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "\n",
    "    subtitle_path = Path(root_path, 'all/subtitle', f'{tt_id}.json')\n",
    "    with open(subtitle_path, 'r') as f_subtitle:\n",
    "        subtitle_json = json.load(f_subtitle)\n",
    "\n",
    "    shot_path = Path(root_path, 'all/shot', f'{tt_id}.json')\n",
    "    with open(shot_path, 'r') as f_shot:\n",
    "        shot_json = json.load(f_shot)\n",
    "\n",
    "    scene_path = Path(root_path, 'all/scene', f'{tt_id}.json')\n",
    "    with open(scene_path, 'r') as f_scene:\n",
    "        scene_json = json.load(f_scene)\n",
    "\n",
    "    shot_shot_sum = shot_json[-1]['shot_id']\n",
    "    scene_shot_sum = scene_json[-1]['shot_end_id'] + 1\n",
    "    \n",
    "    if (shot_shot_sum != scene_shot_sum):\n",
    "        tmp_scene_ele = {\n",
    "            \"scene_id\": scene_json[-1][\"scene_id\"] + 1 ,\n",
    "            \"shot_start_id\": scene_json[-1][\"shot_end_id\"] ,\n",
    "            \"shot_end_id\": shot_shot_sum +1\n",
    "        }\n",
    "        scene_json.append(tmp_scene_ele)\n",
    "        if DEBUG:\n",
    "            print(scene_json)\n",
    "        else:\n",
    "            with open(scene_path, 'w') as f_scene:\n",
    "                json.dump(scene_json, f_scene, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. scene [start, end) -> [start, end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "\n",
    "    scene_path = Path(root_path, 'all/scene', f'{tt_id}.json')\n",
    "    with open(scene_path, 'r') as f_scene:\n",
    "        scene_json = json.load(f_scene)\n",
    "\n",
    "    for scene_ele in scene_json:\n",
    "        shot_id_list = [scene_ele['shot_start_id'], scene_ele['shot_end_id']-1]\n",
    "        scene_ele['shot_id'] = shot_id_list\n",
    "        scene_ele.pop('shot_start_id')\n",
    "        scene_ele.pop('shot_end_id')\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(scene_json)\n",
    "    else:\n",
    "        with open(scene_path, 'w') as f_scene:\n",
    "            json.dump(scene_json, f_scene, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. add /all/synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_order = re.compile('(?<=_)\\d+')\n",
    "\n",
    "def story_id_renew(story_ori_id:str) -> int:\n",
    "    story_id = int(story_order.search(story_ori_id).group(0))\n",
    "    return story_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "\n",
    "    anno_path = Path(ori_path, 'annotation.v1/annotation', f'{tt_id}.json')\n",
    "    with open(anno_path, 'r') as f_anno:\n",
    "        anno_json = json.load(f_anno)\n",
    "\n",
    "    story = anno_json['story']\n",
    "    syno_json = []\n",
    "\n",
    "    for story_ele in story:\n",
    "        syno_json_ele = {\n",
    "            'synopsis_id': story_id_renew(story_ele['id']) ,\n",
    "            'shot_id' : [story_ele['shot'][0], story_ele['shot'][1] - 1] ,\n",
    "            'scentence' : story_ele['description']\n",
    "            }\n",
    "\n",
    "        syno_json.append(syno_json_ele)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(syno_json)\n",
    "    else:\n",
    "        syno_path = Path(root_path, 'all/synopsis', f'{tt_id}.json')\n",
    "        with open(syno_path, 'w') as f_syno:\n",
    "            json.dump(syno_json, f_syno, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_path, shot_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(scene_path , 'w') as f_scene:\n",
    "    json.dump(scene_json, f_scene, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. add shot tail scene_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0120689']):\n",
    "\n",
    "    shot_path = Path(root_path, 'all/shot', f'{tt_id}.json')\n",
    "    with open(shot_path, 'r') as f_shot:\n",
    "        shot_json = json.load(f_shot)\n",
    "\n",
    "    last_scene_id = 0\n",
    "    for shot_ele in shot_json:\n",
    "        if shot_ele[\"scene_id\"]:\n",
    "            last_scene_id = shot_ele[\"scene_id\"]\n",
    "        else: \n",
    "            shot_ele[\"scene_id\"] = last_scene_id + 1\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(shot_json)\n",
    "    else:\n",
    "        with open(shot_path, 'w') as f_shot:\n",
    "            json.dump(shot_json, f_shot, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. add info synopsis_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_path = Path(root_path, 'movie_info.json')\n",
    "with open(info_path, 'r') as f_info:\n",
    "    info_json = json.load(f_info)\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "\n",
    "    synopsis_path = Path(root_path, 'all/synopsis', f'{tt_id}.json')\n",
    "    with open(synopsis_path, 'r') as f_synopsis:\n",
    "        synopsis_json = json.load(f_synopsis)\n",
    "\n",
    "    info_json[tt_id]['synopsis_num'] = int(synopsis_json[-1]['synopsis_id']) + 1\n",
    "\n",
    "    if DEBUG :\n",
    "        print(info_json)\n",
    "    else:\n",
    "        with open(info_path, 'w') as f_info:\n",
    "            json.dump(info_json, f_info, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. retrieval cast and cast_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "### retrival cast\n",
    "meta_root_path = Path('/home/jianghui/dataset/MovieNet/meta.v1/meta/')\n",
    "anno_root_path = Path('/home/jianghui/dataset/MovieNet/annotation.v1/annotation/')\n",
    "cast_root_path = Path(root_path, 'all/cast/')\n",
    "\n",
    "prog = re.compile('(?<=_)\\d+')\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "    print(f'processing {tt_id} ...')\n",
    "\n",
    "    meta_path = Path(meta_root_path, f'{tt_id}.json')\n",
    "    anno_path = Path(anno_root_path, f'{tt_id}.json')\n",
    "    cast_path = Path(cast_root_path, f'{tt_id}.json')\n",
    "    \n",
    "    cast_json = {\"cast_pid\": [], \"cast_bbox\":[]}\n",
    "\n",
    "    with open(meta_path, 'r') as f_meta:\n",
    "        meta_json = json.load(f_meta)\n",
    "    \n",
    "    with open(anno_path, 'r') as f_anno:\n",
    "        anno_json = json.load(f_anno)\n",
    "\n",
    "    cast_json['cast_pid'] = [ i['id'] for i in meta_json['cast'] ]\n",
    "    cast_json['cast_bbox'] = [{\n",
    "        'cast_id':int(prog.search(i['id']).group(0)),\n",
    "        'cast_pid':i['pid'],\n",
    "        'shot_id':i['shot_idx'],\n",
    "        'img_id':i['img_idx'],\n",
    "        'bbox':i[\"body\"][\"bbox\"],\n",
    "        } for i in anno_json['cast']]\n",
    "\n",
    "    with open(cast_path, 'w') as f_cast:\n",
    "        json.dump(cast_json, f_cast, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [{\"id\":123, \"key\":452346}, {\"id\":143, \"key\":4523426}, {\"id\":323, \"key\":424356}, {\"id\":143, \"key\":4456}]\n",
    "f = [ {'id' : i['id']} for i in a ]\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "anno_root_path = Path('/home/jianghui/dataset/MovieNet/annotation.v1/annotation/')\n",
    "no_cast_list = []\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "    anno_path = Path(anno_root_path, f'{tt_id}.json')\n",
    "    with open(anno_path, 'r') as f_anno:\n",
    "        anno_json = json.load(f_anno)\n",
    "\n",
    "    type_dict = set()\n",
    "    try:\n",
    "        for i in anno_json['cast']:\n",
    "            type_dict.add(f'{i[\"resolution\"][0]}-{i[\"resolution\"][1]}')\n",
    "            info_json[tt_id]['resolution'] = i[\"resolution\"]\n",
    "\n",
    "        if len(type_dict) != 1: print(f'{tt_id} has more than one resolution')\n",
    "    except TypeError:\n",
    "        print(f'{tt_id} do not have cast')\n",
    "        no_cast_list.append(tt_id)\n",
    "\n",
    "with open(info_path, 'w') as f_info:\n",
    "    json.dump(info_json, f_info, indent=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. del no cast tt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list = list(set(tt_list).difference(set(no_cast_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list.sort()\n",
    "\n",
    "with open(Path(root_path, 'movie_id_list'), 'w') as f_tt_list:\n",
    "    for tt_line in tt_list:\n",
    "        f_tt_list.write(tt_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_cast_id in no_cast_list:\n",
    "    synopsis_path = Path(root_path, 'all/synopsis', f'{no_cast_id}.json')\n",
    "    synopsis_path.unlink()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. add cast id to subtitle id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "\n",
    "    names = locals()\n",
    "    types = 'cast'\n",
    "    names[f'{types}_path'] = Path(names[f'{types}_root_path'], f'{tt_id}.json')\n",
    "    with open(names[f'{types}_path'], 'r') as names[f'f_{types}']:\n",
    "        names[f'{types}_json'] = json.load(names[f'f_{types}'])\n",
    "    \n",
    "    cast_pid_list = cast_json['cast_pid']\n",
    "    cast_pid_real_list = set()\n",
    "\n",
    "    for cast_bbox in cast_json['cast_bbox']:\n",
    "        if cast_bbox['cast_pid'] == None:\n",
    "            cast_bbox['cast_pid'] = 'others'\n",
    "        cast_pid_real_list.add(cast_bbox['cast_pid'])\n",
    "    \n",
    "    cast_pid_real_list = list(cast_pid_real_list)\n",
    "    cast_pid_real_list.sort()\n",
    "    \n",
    "    cast_json['cast_pid'] = cast_pid_real_list\n",
    "\n",
    "    names[f'{types}_path'] = Path(names[f'{types}_root_path'], f'{tt_id}.json')\n",
    "    with open(names[f'{types}_path'], 'w') as names[f'f_{types}']:\n",
    "        json.dump(names[f'{types}_json'], names[f'f_{types}'], indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here make open_json and svae_json to make coding easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(types:str, tt_id):\n",
    "    names[f'{types}_path'] = Path(names[f'{types}_root_path'], f'{tt_id}.json')\n",
    "    with open(names[f'{types}_path'], 'r') as names[f'f_{types}']:\n",
    "        names[f'{types}_json'] = json.load(names[f'f_{types}'])\n",
    "    return names[f'{types}_json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_root_path = Path(root_path, 'all/shot/')\n",
    "scene_root_path = Path(root_path, 'all/scene/')\n",
    "subtitle_root_path = Path(root_path, 'all/subtitle/')\n",
    "synopsis_root_path = Path(root_path, 'all/synopsis/')\n",
    "cast_root_path = Path(root_path, 'all/cast/')\n",
    "names = locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(types:str, tt_id):\n",
    "    names[f'{types}_path'] = Path(names[f'{types}_root_path'], f'{tt_id}.json')\n",
    "    with open(names[f'{types}_path'], 'w') as names[f'f_{types}']:\n",
    "        json.dump(names[f'{types}_json'], names[f'f_{types}'], indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "    print(f'processing {tt_id} ...')\n",
    "\n",
    "    cast_json = open_json('cast', tt_id)\n",
    "    shot_json = open_json('shot', tt_id)\n",
    "    subtitle_json = open_json('subtitle', tt_id)\n",
    "\n",
    "    for shot_ele in shot_json:\n",
    "        shot_ele['cast_pid'] = []\n",
    "\n",
    "    for cast_bbox_ele in cast_json['cast_bbox']:\n",
    "        shot_json[cast_bbox_ele['shot_id']]['cast_pid'].append(cast_bbox_ele['cast_pid'])\n",
    "\n",
    "    for shot_ele in shot_json:\n",
    "        shot_ele['cast_pid'] = list(set(shot_ele['cast_pid']))\n",
    "\n",
    "    save_json('shot', tt_id)\n",
    "\n",
    "    # ---\n",
    "\n",
    "    for subtitle_ele in subtitle_json:\n",
    "        subtitle_ele['cast_pid'] = []\n",
    "    \n",
    "    for shot_ele in shot_json:\n",
    "        if shot_ele['subtitle_id'] == []: continue\n",
    "        try:\n",
    "            shot_ele['cast_pid']\n",
    "        except:\n",
    "            print(f'{shot_ele} do not have cast_pid')\n",
    "        for subtitle_id in range(shot_ele['subtitle_id'][0], shot_ele['subtitle_id'][1] + 1):\n",
    "            for cast_pid in shot_ele['cast_pid']:\n",
    "                subtitle_json[subtitle_id]['cast_pid'].append(cast_pid)\n",
    "\n",
    "    for subtitle_ele in subtitle_json:\n",
    "        subtitle_ele['cast_pid'] = list(set(subtitle_ele['cast_pid']))\n",
    "\n",
    "    save_json('subtitle', tt_id)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "    print(f'processing {tt_id} ...')\n",
    "\n",
    "    subtitle_json = open_json('subtitle', tt_id)\n",
    "\n",
    "    for subtitle_ele in subtitle_json:\n",
    "        subtitle_ele.pop('cast_pid')\n",
    "\n",
    "    save_json('subtitle', tt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "    print(f'processing {tt_id} ...')\n",
    "\n",
    "    shot_json = open_json('shot', tt_id)\n",
    "    synopsis_json = open_json('synopsis', tt_id)\n",
    "\n",
    "    for synopsis_ele in synopsis_json:\n",
    "        scene_start_id = shot_json[synopsis_ele['shot_id'][0]]['scene_id']\n",
    "        scene_end_id = shot_json[synopsis_ele['shot_id'][1]]['scene_id']\n",
    "        synopsis_ele['scene_id']=[scene_start_id, scene_end_id]\n",
    "        \n",
    "    save_json('synopsis', tt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing tt0047396 ...\n",
      "processing tt0048545 ...\n",
      "processing tt0049730 ...\n",
      "processing tt0052357 ...\n",
      "processing tt0056923 ...\n",
      "processing tt0061418 ...\n",
      "processing tt0061722 ...\n",
      "processing tt0062622 ...\n",
      "processing tt0063442 ...\n",
      "processing tt0065214 ...\n",
      "processing tt0065724 ...\n",
      "processing tt0066026 ...\n",
      "processing tt0067116 ...\n",
      "processing tt0068646 ...\n",
      "processing tt0070735 ...\n",
      "processing tt0071315 ...\n",
      "processing tt0071562 ...\n",
      "processing tt0072684 ...\n",
      "processing tt0073195 ...\n",
      "processing tt0074285 ...\n",
      "processing tt0075148 ...\n",
      "processing tt0076759 ...\n",
      "processing tt0077405 ...\n",
      "processing tt0078788 ...\n",
      "processing tt0078841 ...\n",
      "processing tt0079417 ...\n",
      "processing tt0080684 ...\n",
      "processing tt0081505 ...\n",
      "processing tt0082089 ...\n",
      "processing tt0082971 ...\n",
      "processing tt0083658 ...\n",
      "processing tt0083929 ...\n",
      "processing tt0084726 ...\n",
      "processing tt0086190 ...\n",
      "processing tt0086250 ...\n",
      "processing tt0086879 ...\n",
      "processing tt0087332 ...\n",
      "processing tt0088847 ...\n",
      "processing tt0088944 ...\n",
      "processing tt0090022 ...\n",
      "processing tt0090605 ...\n",
      "processing tt0090756 ...\n",
      "processing tt0091042 ...\n",
      "processing tt0093565 ...\n",
      "processing tt0093779 ...\n",
      "processing tt0094737 ...\n",
      "processing tt0095016 ...\n",
      "processing tt0096320 ...\n",
      "processing tt0096895 ...\n",
      "processing tt0097428 ...\n",
      "processing tt0097576 ...\n",
      "processing tt0098724 ...\n",
      "processing tt0099423 ...\n",
      "processing tt0099487 ...\n",
      "processing tt0099674 ...\n",
      "processing tt0099685 ...\n",
      "processing tt0100157 ...\n",
      "processing tt0100405 ...\n",
      "processing tt0100802 ...\n",
      "processing tt0101272 ...\n",
      "processing tt0103074 ...\n",
      "processing tt0103772 ...\n",
      "processing tt0103776 ...\n",
      "processing tt0104257 ...\n",
      "processing tt0104348 ...\n",
      "processing tt0105236 ...\n",
      "processing tt0105695 ...\n",
      "processing tt0107290 ...\n",
      "processing tt0107808 ...\n",
      "processing tt0107822 ...\n",
      "processing tt0108160 ...\n",
      "processing tt0108330 ...\n",
      "processing tt0108399 ...\n",
      "processing tt0109686 ...\n",
      "processing tt0110074 ...\n",
      "processing tt0112641 ...\n",
      "processing tt0113243 ...\n",
      "processing tt0113277 ...\n",
      "processing tt0114369 ...\n",
      "processing tt0114388 ...\n",
      "processing tt0114558 ...\n",
      "processing tt0114814 ...\n",
      "processing tt0115759 ...\n",
      "processing tt0115798 ...\n",
      "processing tt0116209 ...\n",
      "processing tt0116367 ...\n",
      "processing tt0116629 ...\n",
      "processing tt0117060 ...\n",
      "processing tt0117500 ...\n",
      "processing tt0117951 ...\n",
      "processing tt0118571 ...\n",
      "processing tt0118636 ...\n",
      "processing tt0118715 ...\n",
      "processing tt0118929 ...\n",
      "processing tt0118971 ...\n",
      "processing tt0119094 ...\n",
      "processing tt0119396 ...\n",
      "processing tt0119488 ...\n",
      "processing tt0119528 ...\n",
      "processing tt0119567 ...\n",
      "processing tt0119822 ...\n",
      "processing tt0120660 ...\n",
      "processing tt0120689 ...\n",
      "processing tt0120735 ...\n",
      "processing tt0120755 ...\n",
      "processing tt0120780 ...\n",
      "processing tt0120815 ...\n",
      "processing tt0120890 ...\n",
      "processing tt0120902 ...\n",
      "processing tt0120915 ...\n",
      "processing tt0121765 ...\n",
      "processing tt0122690 ...\n",
      "processing tt0123755 ...\n",
      "processing tt0126886 ...\n",
      "processing tt0128445 ...\n",
      "processing tt0129387 ...\n",
      "processing tt0134119 ...\n",
      "processing tt0137523 ...\n",
      "processing tt0139654 ...\n",
      "processing tt0142688 ...\n",
      "processing tt0145487 ...\n",
      "processing tt0159365 ...\n",
      "processing tt0163025 ...\n",
      "processing tt0164052 ...\n",
      "processing tt0167190 ...\n",
      "processing tt0167404 ...\n",
      "processing tt0169547 ...\n",
      "processing tt0172495 ...\n",
      "processing tt0180073 ...\n",
      "processing tt0183649 ...\n",
      "processing tt0186151 ...\n",
      "processing tt0187393 ...\n",
      "processing tt0190332 ...\n",
      "processing tt0208092 ...\n",
      "processing tt0209144 ...\n",
      "processing tt0209958 ...\n",
      "processing tt0213149 ...\n",
      "processing tt0217505 ...\n",
      "processing tt0244244 ...\n",
      "processing tt0246578 ...\n",
      "processing tt0258463 ...\n",
      "processing tt0264395 ...\n",
      "processing tt0281358 ...\n",
      "processing tt0286106 ...\n",
      "processing tt0288477 ...\n",
      "processing tt0311113 ...\n",
      "processing tt0315327 ...\n",
      "processing tt0319061 ...\n",
      "processing tt0329101 ...\n",
      "processing tt0338013 ...\n",
      "processing tt0343818 ...\n",
      "processing tt0349903 ...\n",
      "processing tt0361748 ...\n",
      "processing tt0363771 ...\n",
      "processing tt0369339 ...\n",
      "processing tt0370263 ...\n",
      "processing tt0372183 ...\n",
      "processing tt0379786 ...\n",
      "processing tt0383574 ...\n",
      "processing tt0407887 ...\n",
      "processing tt0408236 ...\n",
      "processing tt0408790 ...\n",
      "processing tt0409459 ...\n",
      "processing tt0421715 ...\n",
      "processing tt0430357 ...\n",
      "processing tt0434409 ...\n",
      "processing tt0435705 ...\n",
      "processing tt0440963 ...\n",
      "processing tt0448157 ...\n",
      "processing tt0454876 ...\n",
      "processing tt0467200 ...\n",
      "processing tt0467406 ...\n",
      "processing tt0479884 ...\n",
      "processing tt0493464 ...\n",
      "processing tt0499549 ...\n",
      "processing tt0758758 ...\n",
      "processing tt0780504 ...\n",
      "processing tt0780571 ...\n",
      "processing tt0790686 ...\n",
      "processing tt0796366 ...\n",
      "processing tt0808151 ...\n",
      "processing tt0815236 ...\n",
      "processing tt0822832 ...\n",
      "processing tt0824747 ...\n",
      "processing tt0848228 ...\n",
      "processing tt0898367 ...\n",
      "processing tt0913425 ...\n",
      "processing tt0945513 ...\n",
      "processing tt0947798 ...\n",
      "processing tt0963794 ...\n",
      "processing tt0964517 ...\n",
      "processing tt0974661 ...\n",
      "processing tt0976051 ...\n",
      "processing tt0985699 ...\n",
      "processing tt0993846 ...\n",
      "processing tt1032755 ...\n",
      "processing tt1037705 ...\n",
      "processing tt1038919 ...\n",
      "processing tt1059786 ...\n",
      "processing tt1068680 ...\n",
      "processing tt1100089 ...\n",
      "processing tt1104001 ...\n",
      "processing tt1119646 ...\n",
      "processing tt1124035 ...\n",
      "processing tt1125849 ...\n",
      "processing tt1182345 ...\n",
      "processing tt1193138 ...\n",
      "processing tt1205489 ...\n",
      "processing tt1210166 ...\n",
      "processing tt1219289 ...\n",
      "processing tt1284575 ...\n",
      "processing tt1291584 ...\n",
      "processing tt1375666 ...\n",
      "processing tt1401152 ...\n",
      "processing tt1403865 ...\n",
      "processing tt1409024 ...\n",
      "processing tt1411238 ...\n",
      "processing tt1412386 ...\n",
      "processing tt1446714 ...\n",
      "processing tt1454029 ...\n",
      "processing tt1591095 ...\n",
      "processing tt1637725 ...\n",
      "processing tt1707386 ...\n",
      "processing tt1800241 ...\n",
      "processing tt1979320 ...\n",
      "processing tt2132285 ...\n",
      "processing tt2140373 ...\n",
      "processing tt2488496 ...\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "for tt_id in (tt_list if not DEBUG else ['tt0047396']):\n",
    "    print(f'processing {tt_id} ...')\n",
    "\n",
    "    cast_json = open_json('cast', tt_id)\n",
    "\n",
    "    cast_json['cast_pid_list'] = cast_json.pop('cast_pid')\n",
    "        \n",
    "    save_json('cast', tt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
